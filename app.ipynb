{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP3. 트레이닝 및 정확도 검사\n",
    "\n",
    "import cv2 as cv\n",
    "import os\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n",
      "68\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "img_w, img_h = 100, 100\n",
    "train_dir = './dataset_img/training_set'\n",
    "test_dir = './dataset_img/test_set'\n",
    "# train_samples = 550\n",
    "train_samples = sum([len(files) for r, d, files in os.walk('./dataset_img/training_set')])\n",
    "# test_samples = 100\n",
    "test_samples = sum([len(files) for r, d, files in os.walk('./dataset_img/test_set')])\n",
    "epochs = 20\n",
    "train_batch_size = 10\n",
    "test_batch_size = 5\n",
    "classnum = len(os.listdir(train_dir))-1\n",
    "\n",
    "print(train_samples)\n",
    "print(test_samples)\n",
    "print(classnum)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (classnum, img_w, img_h)\n",
    "else:\n",
    "    input_shape = (img_w, img_h, classnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create the model\n",
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(img_w, img_h, 3))\n",
    "# for layer in vgg_conv.layers[:-4]: layer.trainable = False\n",
    "# for layer in vgg_conv.layers:\n",
    "#     print(layer, layer.trainable)\n",
    "for layer in vgg_conv.layers: layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(vgg_conv)\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(classnum, activation='sigmoid'))\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 501 images belonging to 3 classes.\n",
      "Found 64 images belonging to 3 classes.\n",
      "Epoch 1/20\n",
      "51/50 [==============================] - 81s 2s/step - loss: 0.0973 - acc: 0.9274 - val_loss: 2.5956 - val_acc: 0.7031\n",
      "Epoch 2/20\n",
      "51/50 [==============================] - 70s 1s/step - loss: 0.0925 - acc: 0.9372 - val_loss: 2.3751 - val_acc: 0.7031\n",
      "Epoch 3/20\n",
      "51/50 [==============================] - 63s 1s/step - loss: 0.0945 - acc: 0.9431 - val_loss: 2.7396 - val_acc: 0.7031\n",
      "Epoch 4/20\n",
      "51/50 [==============================] - 68s 1s/step - loss: 0.0941 - acc: 0.9490 - val_loss: 2.7767 - val_acc: 0.7031\n",
      "Epoch 5/20\n",
      "51/50 [==============================] - 93s 2s/step - loss: 0.0931 - acc: 0.9412 - val_loss: 2.1387 - val_acc: 0.7031\n",
      "Epoch 6/20\n",
      "51/50 [==============================] - 77s 2s/step - loss: 0.1003 - acc: 0.9313 - val_loss: 3.1787 - val_acc: 0.7031\n",
      "Epoch 7/20\n",
      "51/50 [==============================] - 73s 1s/step - loss: 0.0990 - acc: 0.9333 - val_loss: 2.3209 - val_acc: 0.7031\n",
      "Epoch 8/20\n",
      "51/50 [==============================] - 81s 2s/step - loss: 0.0945 - acc: 0.9412 - val_loss: 2.4105 - val_acc: 0.7031\n",
      "Epoch 9/20\n",
      "51/50 [==============================] - 71s 1s/step - loss: 0.1074 - acc: 0.9431 - val_loss: 3.2244 - val_acc: 0.7031\n",
      "Epoch 10/20\n",
      "51/50 [==============================] - 69s 1s/step - loss: 0.0956 - acc: 0.9372 - val_loss: 2.9176 - val_acc: 0.7031\n",
      "Epoch 11/20\n",
      "51/50 [==============================] - 70s 1s/step - loss: 0.1069 - acc: 0.9372 - val_loss: 3.0448 - val_acc: 0.7031\n",
      "Epoch 12/20\n",
      "51/50 [==============================] - 71s 1s/step - loss: 0.0922 - acc: 0.9333 - val_loss: 2.8427 - val_acc: 0.7031\n",
      "Epoch 13/20\n",
      "51/50 [==============================] - 73s 1s/step - loss: 0.0898 - acc: 0.9313 - val_loss: 3.5839 - val_acc: 0.7031\n",
      "Epoch 14/20\n",
      "51/50 [==============================] - 70s 1s/step - loss: 0.0869 - acc: 0.9353 - val_loss: 3.1313 - val_acc: 0.7031\n",
      "Epoch 15/20\n",
      "51/50 [==============================] - 66s 1s/step - loss: 0.0915 - acc: 0.9333 - val_loss: 3.5684 - val_acc: 0.7031\n",
      "Epoch 16/20\n",
      "51/50 [==============================] - 64s 1s/step - loss: 0.0910 - acc: 0.9372 - val_loss: 3.3362 - val_acc: 0.7031\n",
      "Epoch 17/20\n",
      "51/50 [==============================] - 61s 1s/step - loss: 0.0955 - acc: 0.9294 - val_loss: 2.8010 - val_acc: 0.7031\n",
      "Epoch 18/20\n",
      "51/50 [==============================] - 61s 1s/step - loss: 0.1062 - acc: 0.9160 - val_loss: 3.0868 - val_acc: 0.7031\n",
      "Epoch 19/20\n",
      "51/50 [==============================] - 62s 1s/step - loss: 0.0970 - acc: 0.9278 - val_loss: 2.6237 - val_acc: 0.7031\n",
      "Epoch 20/20\n",
      "51/50 [==============================] - 61s 1s/step - loss: 0.0962 - acc: 0.9313 - val_loss: 3.0456 - val_acc: 0.7031\n"
     ]
    }
   ],
   "source": [
    "# 2. create dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "#                                   rotation_range=15,\n",
    "#                                   width_shift_range=0.1,\n",
    "#                                   height_shift_range=0.1,\n",
    "#                                   # shear_range=0.5,\n",
    "#                                   # zoom_range=[0.8, 2.0],\n",
    "#                                   horizontal_flip=True,\n",
    "#                                 #   vertical_flip=True,\n",
    "#                                   fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (img_w, img_h),\n",
    "    batch_size = train_batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (img_w, img_h),\n",
    "    batch_size = test_batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "# 3. set the model learning\n",
    "# optimizer=adam\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])\n",
    "\n",
    "# 4. learn the model\n",
    "model.fit_generator(train_generator,\n",
    "                    # steps_per_epoch = train_samples\n",
    "                    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = test_generator,\n",
    "                    # validation_steps = test_batch_size\n",
    "                    validation_steps=test_generator.samples/test_generator.batch_size,\n",
    "                    verbose=1)\n",
    "# model.save_weights('test2.h5')\n",
    "model.save('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate(정확도) --\n",
      "acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# 5. evaluate the model\n",
    "print(\"-- Evaluate(정확도) --\")\n",
    "scores = model.evaluate_generator(test_generator, steps=5)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모든 자원을 해제\n",
    "# cap.release()\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/12 [==============================] - 7s 571ms/step\n",
      "No of errors = 19/64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# STEP4. 정답 틀린 이미지 보여주기\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the filenames from the generator\n",
    "fnames = test_generator.filenames\n",
    "\n",
    "# Get the ground truth from generator\n",
    "ground_truth = test_generator.classes\n",
    "\n",
    "# Get the label to class mapping from the generator\n",
    "label2index = test_generator.class_indices\n",
    "\n",
    "# Getting the mapping from class index to class label\n",
    "idx2label = dict((v,k) for k,v in label2index.items())\n",
    "\n",
    "# Get the predictions from the model using the generator\n",
    "predictions = model.predict_generator(test_generator, steps=test_generator.samples/test_generator.batch_size,verbose=1)\n",
    "predicted_classes = np.argmax(predictions,axis=1)\n",
    "\n",
    "errors = np.where(predicted_classes != ground_truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors),test_generator.samples))\n",
    "\n",
    "# Show the errors\n",
    "for i in range(len(errors)):\n",
    "    pred_class = np.argmax(predictions[errors[i]])\n",
    "    pred_label = idx2label[pred_class]\n",
    "    \n",
    "    title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
    "        fnames[errors[i]].split('/')[0],\n",
    "        pred_label,\n",
    "        predictions[errors[i]][pred_class])\n",
    "    \n",
    "    original = load_img('{}/{}'.format(test_dir,fnames[errors[i]]))\n",
    "    plt.figure(figsize=[7,7])\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.imshow(original)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 images belonging to 3 classes.\n",
      "-- Predict --\n",
      "[0, 0, 5]\n",
      "100.0 %의 확률로 soyoung\n"
     ]
    }
   ],
   "source": [
    "# STEP5. guess\n",
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# 1. data 준비\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# 검증용 generator 생성\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        './dataset_img/test_set',\n",
    "        target_size=(img_w, img_h),\n",
    "        batch_size=1,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# 2. call model\n",
    "from keras.models import load_model\n",
    "# model = load_weights('test2.h5')\n",
    "model = load_model('test.h5')\n",
    "\n",
    "# 3. use model\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "# print(\"//\")\n",
    "# print(test_generator.class_indices)\n",
    "# print(output)\n",
    "# print(\"//\")\n",
    "class_list = list(test_generator.class_indices.keys())\n",
    "res_list = [0]*len(test_generator.class_indices)\n",
    "for res in output:\n",
    "    tmp = list(map(float,str(res)[1:len(str(res))-1].split()))\n",
    "    max_index = tmp.index(max(tmp))\n",
    "    res_list[max_index]+=1\n",
    "print(res_list)\n",
    "print(max(res_list)/sum(res_list)*100,\"%의 확률로\",class_list[res_list.index(max(res_list))])\n",
    "# print(class_list[res_list.index(max(res_list))])\n",
    "# print(\"ans:\",class_list(res_list.index(max(res_list))))\n",
    "# print(test_generator.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
